{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cca911b3",
   "metadata": {},
   "source": [
    "**_Autor_**: Rubén del Mazo Rodríguez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f18ff30",
   "metadata": {},
   "source": [
    "# Implementación efectiva de redes neuronales\n",
    "Una de las razones por las que los investigadores del aprendizaje profundo han sido capaces de escalar las redes neuronales, y desarrollar redes neuronales realmente grandes durante las últimas décadas, es debido a que las redes neuronales se pueden vectorizar. Se pueden implementar de forma muy eficiente utilizando multiplicaciones matriciales y resulta que el hardware de computación paralela, incluidas las GPU, pero también algunas funciones de CPU, son muy buenas haciendo multiplicaciones matriciales muy grandes. A continuación, veamos cómo funcionan estas implementaciones vectorizadas de redes neuronales. Sin estas ideas, es probable que el aprendizaje profundo no se acercara ni de lejos al éxito y la escala actuales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b2cc45",
   "metadata": {},
   "source": [
    "## Tabla de contenidos\n",
    "- [Aclaraciones sobre los arrays de numpy y sus dimensiones](#1)\n",
    "- [Breve repaso de conceptos del álgebra](#2)\n",
    "    - [Producto escalar](#2-1)\n",
    "        - [np.dot()](#2-1-1)\n",
    "    - [Multiplicación matricial](#2-2)\n",
    "        - [np.matmul()](#2-2-1)\n",
    "        - [a @ b](#2-2-2)\n",
    "- [Vectorización en redes neuronales](#3)\n",
    "    - [Cálculo de z](#3-0)\n",
    "    - [Propragación hacia delante / _forward propagation_](#3-1)\n",
    "    - [Implementación de las funciones de pérdida L1 y L2](#3-2)\n",
    "        - [L1](#3-2-1)\n",
    "        - [L2](#3-2-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bae9da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos librerias\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb22268",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "### Aclaraciones sobre los arrays de numpy y sus dimensiones\n",
    "NumPy es una biblioteca, creada en 2005, que se ha convertido en el estándar para el álgebra lineal en Python. Un hecho desafortunado sobre cómo se programa hoy en día es que hay bibliotecas que son utilizadas ampliamente para el aprendizaje profundo, como es TensorFlow, que utilizan NumPy y fueron creadas posteriormente, pero que son inconsistentes en cómo se representan los datos con respecto a NumPy. Por lo tanto, es importante conocer cómo se representa el álgebra lineal con NumPy a la hora de utilizarlo, tanto en solitario como con bibliotecas tan famosas como TensorFlow.\n",
    "\n",
    "Veamos la representación de vectores y matrices en NumPy. Una matriz es un arreglo rectangular de magnitudes dispuestas en filas y columnas. Por convención, _n_ filas por _m_ columnas, _n x m_. Es importante mencionar que un vector se diferencia de una matriz en que una de sus dimensiones es adimensional (de magnitud uno), es decir, _n x 1_ o _1 x m_. Para crear matrices en dos dimensiones, hay que **utilizar doble corchete**: el primer corchete indica que se alberga la matriz, mientras que los siguientes corchetes albergan los números (o símbolos) que componen cada fila. Cada fila está separada por comas dentro del primer corchete. El número de columnas es el número de elementos de cada fila y este número tiene que ser el mismo en cada fila. En caso contrario, como es lógico, saltaría un error. Las dimensiones se pueden visualizar y utilizar en Python con la instrucción `.shape`.\n",
    "\n",
    "En el caso de los vectores, si queremos que sea un vector 2D (y, por tanto, que siga siendo una matriz), hay que utilizar el doble corchete. Si solo utilizamos un corchete, estaríamos ante un **vector 1D**. Y he aquí la diferencia principal que hace importante esta aclaración sobre NumPy, porque bibliotecas como TensorFlow **trabajan con notación matricial** y no pueden trabajar con vectores 1D. TensorFlow fue diseñado para manejar conjuntos de datos muy grandes mediante la representación de los datos en matrices en lugar de matrices 1D, lo que permite a TensorFlow ser un poco más eficiente computacionalmente internamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c851e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "(2, 3)\n",
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo matriz 2x3\n",
    "matriz_dos_por_tres = np.array([[1, 2, 3],\n",
    "                                [4, 5, 6]])\n",
    "matriz_dos_por_tres_equivalente = np.array([[1, 2, 3],[4, 5, 6]])\n",
    "\n",
    "print(matriz_dos_por_tres)\n",
    "print(matriz_dos_por_tres_equivalente)\n",
    "print(matriz_dos_por_tres.shape)\n",
    "print(matriz_dos_por_tres_equivalente.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "319ff28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.   2. ]\n",
      " [-3.  -4. ]\n",
      " [-0.5 -0.6]\n",
      " [ 6.   7. ]]\n",
      "(4, 2)\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo matriz 4x2. En Python, puede haber int y double en la misma matriz, pero recordemos que los int se convertirán en doubles\n",
    "# y será una matriz de doubles.\n",
    "matriz_cuatro_por_dos = np.array([[1, 2], [-3.0, -4.0], [-0.5, -0.6], [6, 7]])\n",
    "\n",
    "print(matriz_cuatro_por_dos)\n",
    "print(matriz_cuatro_por_dos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e1df3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100  15]]\n",
      "(1, 2)\n",
      "[[100]\n",
      " [ 15]]\n",
      "(2, 1)\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo vectores 1x2 y 2x1\n",
    "vector_uno_por_dos = np.array([[100, 15]])\n",
    "vector_dos_por_uno = np.array([[100], [15]])\n",
    "\n",
    "print(vector_uno_por_dos)\n",
    "print(vector_uno_por_dos.shape)\n",
    "print(vector_dos_por_uno)\n",
    "print(vector_dos_por_uno.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ebab8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100  15]\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo vector 1D\n",
    "vector_unidimensional = np.array([100, 15])\n",
    "\n",
    "print(vector_unidimensional)\n",
    "print(vector_unidimensional.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b4816b",
   "metadata": {},
   "source": [
    "Como se puede observar en el último ejemplo, la dimensión devuelta es (2,), puesto que solo tiene una dimensión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f20fba1",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "### Breve repaso de conceptos del álgebra\n",
    "<a name='2-1'></a>\n",
    "##### Producto escalar\n",
    "El producto escalar de dos vectores equivale al producto del traspuesto del primero por el segundo, teniendo en cuenta que el producto se realiza elemento por elemento. Esto es útil para comprender la multiplicación matricial.\n",
    "\n",
    "$$z = \\vec{a}·\\vec{w}$$  equivale a $$z = \\vec{a}^T * \\vec{w}$$\n",
    "\n",
    "Ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abd7df44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Productor escalar: 11\n",
      "Multiplicación traspuesta del primero por el segundo: 11\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2])\n",
    "w = np.array([3,4])\n",
    "\n",
    "print(f'Productor escalar: {np.dot(a,w)}')\n",
    "print(f'Multiplicación traspuesta del primero por el segundo: {np.sum(a.T*w)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a9b415",
   "metadata": {},
   "source": [
    "<a name='2-1-1'></a>\n",
    "##### np.dot()\n",
    "\n",
    "`numpy.dot(a, b, out=None)`\n",
    "\n",
    "Producto escalar de dos matrices. Específicamente,\n",
    "\n",
    "- Si a y b son matrices 1-D, es el producto interior de vectores (sin conjugación compleja).\n",
    "\n",
    "- Si a y b son matrices bidimensionales, es una multiplicación de matrices, pero es preferible utilizar `np.matmul` o `a @ b`.\n",
    "\n",
    "Fuente: https://numpy.org/doc/stable/reference/generated/numpy.dot.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906eadca",
   "metadata": {},
   "source": [
    "<a name='2-2'></a>\n",
    "#### Multiplicación matricial\n",
    "\n",
    "Recordemos que la multiplicación matricial sigue la regla: **(n,k)\\*(k,m) = (n,m)**. Es decir, la primera matriz tiene que tener el mismo número de columnas que número de filas tiene la segunda.\n",
    "\n",
    "Para la **multiplicación de un vector 1D por una matriz**, el vector debe tener el mismo número de elementos que filas la matriz (k,m). En caso de ser un vector fila, es decir, (k,1), se coge el vector traspuesto:\n",
    "\n",
    "$$ Z = \\vec{a}^T * W = [\\vec{a}^T*w_1, ..., \\vec{a}^T*w_m, \\vec{a}^T*w_m] $$\n",
    "\n",
    "siendo $w_i$ cada vector columna que compone la matriz W y _m_ el número de columnas de la matriz.\n",
    "\n",
    "En el **caso general** de multiplicación matriz por matriz, se multiplica cada fila de la primera por cada columna de la segunda. Es decir, si consideramos la matriz _A_ como un conjunto de vectores fila y la matriz _W_ como un conjunto de vectores columna:\n",
    "\n",
    "$$ A = (\\vec{F_1}, \\vec{F_2}, ..., \\vec{F_n)} $$\n",
    "$$ W = (\\vec{C_1}, \\vec{C_2}, ..., \\vec{C_m)} $$\n",
    "\n",
    "el producto de estas matrices será:\n",
    "\n",
    "$$ A*W = \n",
    "\\begin{pmatrix}\n",
    "\\vec{F_1}*\\vec{C_1} & \\vec{F_1}*\\vec{C_2} & ... & \\vec{F_1}*\\vec{C_m} \\\\\n",
    "\\vec{F_2}*\\vec{C_1} & \\vec{F_2}*\\vec{C_2} & ... & \\vec{F_2}*\\vec{C_m} \\\\\n",
    "... & ... & ... & ...\\\\\n",
    "\\vec{F_n}*\\vec{C_1} & \\vec{F_n}*\\vec{C_2} & ... & \\vec{F_n}*\\vec{C_m}\n",
    "\\end{pmatrix} $$\n",
    "\n",
    "Hay un **matiz importante** en el aprendizaje automático. Como se ve en este trabajo, los valores, datos, etc se colocan/apilan en las matrices como vectores columna. Entonces, para que el resultado de los cálculos de la red neuronal sean correctos (por ejemplo, imaginemos que estamos multiplicando la matriz de datos de entrada por la matriz de pesos), hay que convertir la primera matriz en una matriz de vectores fila. Para eso se hace la traspuesta con `.T` y ya se podría realizar el cálculo. En las dos siguientes figuras se muestra un ejemplo:\n",
    "\n",
    "<img src=\"imagenes/matriz_traspuesta.png\" style=\"width:110px;height:80px;\">\n",
    "<caption><center><b>Figura 1</b></center></caption><br>\n",
    "\n",
    "<img src=\"imagenes/multiplicacion_traspuesta.png\" style=\"width:280px;height:80px;\">\n",
    "<caption><center><b>Figura 2</b></center></caption><br>\n",
    "\n",
    "<img src=\"imagenes/resultado.png\" style=\"width:140px;height:70px;\">\n",
    "<caption><center><b>Figura 3</b></center></caption><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfde1edb",
   "metadata": {},
   "source": [
    "Veamos cómo aplicarla con Python y NumPy. Para más información y casos, consultar la documentación.\n",
    "<a name='2-2-1'></a>\n",
    "##### np.matmul()\n",
    "\n",
    "`numpy.matmul(x1, x2, /, out=None, ...)`\n",
    "\n",
    "Producto matricial de dos matrices.\n",
    "\n",
    "- Si ambos argumentos son bidimensionales, se multiplican como las matrices convencionales.\n",
    "\n",
    "- Si el primer argumento es 1-D, se convierte en una matriz añadiendo un 1 a sus dimensiones. Tras la multiplicación matricial, se elimina el 1 antepuesto.\n",
    "\n",
    "- Si el segundo argumento es 1-D, se convierte en una matriz añadiendo un 1 a sus dimensiones. Tras la multiplicación matricial, se elimina el 1 añadido.\n",
    "\n",
    ".matmul difiere de .dot en dos aspectos importantes:\n",
    "\n",
    "- No se permite la multiplicación por escalares, en su lugar utilice *.\n",
    "\n",
    "- Las pilas de matrices se emiten juntas como si las matrices fueran elementos, respetando la regla (n,k)x(k,m)->(n,m):\n",
    "\n",
    "La función matmul implementa la semántica del operador @ introducido en Python 3.5.\n",
    "\n",
    "Fuente: https://numpy.org/doc/stable/reference/generated/numpy.matmul.html#numpy.matmul\n",
    "\n",
    "<a name='2-2-2'></a>\n",
    "##### a @ b\n",
    "\n",
    "El operador @ puede utilizarse como abreviatura de np.matmul() en ndarrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd880314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión del producto AT*W: (3, 4)\n",
      "¿Es equivalente np.matmul y @?: True\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo\n",
    "# Matriz 2x3\n",
    "A = np.array([[1,-1,2],\n",
    "              [2,-2,1]])\n",
    "# Matriz 3x2\n",
    "AT = A.T\n",
    "# Matriz 2x4\n",
    "W = np.array([[3,5,7,9],\n",
    "              [4,6,8,10]])\n",
    "# Multiplicación de matrices\n",
    "Z1 = np.matmul(AT,W)\n",
    "Z2 = AT @ W\n",
    "\n",
    "print(f'Dimensión del producto AT*W: {Z1.shape}')\n",
    "print(f'¿Es equivalente np.matmul y @?: {np.array_equal(Z1,Z2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e29395",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "### Vectorización en redes neuronales\n",
    "\n",
    "La vectorización es, en pocas palabras, el arte de deshacerse de los bucles `for` explícitos en el código. En la era del aprendizaje profundo, especialmente en la práctica, a menudo los conjuntos de datos de entrenamiento son relativamente grandes, dado que es cuando los algoritmos de aprendizaje profundo tienden a destacar. Por lo tanto, es importante que el código se ejecute los más rápidamente posible porque, de lo contrario, si se está entrenando un gran conjunto de datos, el código puede tardar mucho tiempo en ejecutarse y obtener el resultado. Así que en la era del aprendizaje profundo, la capacidad de realizar la vectorización se ha convertido en una habilidad clave.\n",
    "\n",
    "<a name='3-0'></a>\n",
    "#### Cálculo de z\n",
    "\n",
    "Recordemos que \"z\" era la combinación lineal de los pesos por las características de cada ejemplo, más un valor umbral: $z = w^Tx + b$. Dados los vectores columna $w \\in \\mathbb{R}^n$ y $x \\in \\mathbb{R}^n$, veamos la forma vectorizada y no vectorizada a la hora de calcular \"z\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94d7b79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250021.19221575942\n",
      "Versión no vectorizada (for loop): 332.0481777191162 ms\n",
      "250021.19221576414\n",
      "Versión vectorizada: 0.9739398956298828 ms\n",
      "La versión vectorizada es 341 veces más rápida que la versión NO vectorizada.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "n = 1000000\n",
    "w = np.random.rand(1000000)\n",
    "x = np.random.rand(1000000)\n",
    "b = 7\n",
    "z = 0\n",
    "\n",
    "t_ini = time.time()\n",
    "# Ejemplo implementacion NO vectorizada\n",
    "for i in range(n):\n",
    "    z += w[i]*x[i]\n",
    "z += b\n",
    "t_fin = time.time()\n",
    "print(z)\n",
    "t_no_vec = 1000*(t_fin - t_ini)\n",
    "print(f'Versión no vectorizada (for loop): {t_no_vec} ms')\n",
    "\n",
    "# Ejemplo implementacion vectorizada\n",
    "z = 0\n",
    "t_ini = time.time()\n",
    "z = np.dot(w,x) + b\n",
    "t_fin = time.time()\n",
    "t_vec = 1000*(t_fin - t_ini)\n",
    "print(z)\n",
    "print(f'Versión vectorizada: {t_vec} ms')\n",
    "\n",
    "print(f'La versión vectorizada es {round(t_no_vec/t_vec)} veces más rápida que la versión NO vectorizada.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cf8d99",
   "metadata": {},
   "source": [
    "No solo la implementación vectorizada es computacionalmente más rápida, sino que además necesita de menos líneas de código."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130bd91a",
   "metadata": {},
   "source": [
    "<a name='3-1'></a>\n",
    "#### Propragación hacia delante / _forward propagation_\n",
    "\n",
    "He aquí un ejemplo de cómo se podría implementar la propagación hacia delante (_forward propagation_) en una sola capa. _x_  es la entrada, _W_, los pesos de la primera, segunda y tercera neuronas y los parámetros de sesgo, _b._ Con los valores numéricos elegidos, obtendremos como resultado tres números."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd43a014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Las matrices por convención se escriben en mayúscula y los vectores en minúscula.\n",
    "x = np.array([200, 17])     # Vector 1D\n",
    "W = np.array([[1, -3, 5],\n",
    "              [-2, 4, -6]]) # Matriz 2x3\n",
    "b = np.array([-1, 1, 2])    # Vector 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87ad4512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a utilizar en el ejemplo una función de activación sigmoide\n",
    "# Para más detalles sobre su funcionamiento, consultar anexo de funciones NumPy\n",
    "def sigmoide(z):\n",
    "    \"\"\"\n",
    "    Calcula la función sigmoide de z\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    z : Un escalar o matriz numpy de cualquier tamaño.\n",
    "\n",
    "    Devuelve\n",
    "    -------\n",
    "     g : sigmoid(z)\n",
    "    \"\"\"\n",
    "    z = np.clip( z, -500, 500 )     # protección contra el desbordamiento\n",
    "    g = np.round(1.0/(1.0+np.exp(-z)))\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2be209e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versión NO VECTORIZADA\n",
    "def forward_propagation(a_entrada, W, B, g):\n",
    "    \"\"\"\n",
    "    Calcula las activaciones de una capa.\n",
    "    \n",
    "    Argumentos:\n",
    "    ----------\n",
    "      a_entrada (ndarray (n, ))  : Datos de entrada \n",
    "      W         (ndarray (n,j))  : Matriz de pesos, n características por unidad, j unidades\n",
    "      b         (ndarray (j, ))  : vector de sesgo, j unidades\n",
    "      g                          : función de activación\n",
    "      \n",
    "    Devuelve\n",
    "    ----------\n",
    "      a_salida  (ndarray (j,))   : j unidades\n",
    "    \"\"\"\n",
    "    unidades = W.shape[1]\n",
    "    a_salida = np.zeros(unidades)\n",
    "    for j in range(unidades):               \n",
    "        w = W[:,j]                                    \n",
    "        z = np.dot(a_entrada, w) + b[j]\n",
    "        # Función de activación g() definida fuera de la función\n",
    "        a_salida[j] = g(z)               \n",
    "    return(a_salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "243cb664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 1.]\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# %%time - Se podría utilizar para ver la diferencia de tiempos de ejecución, pero esta diferencia se nota con entradas numéricas grandes.\n",
    "\n",
    "a_salida = forward_propagation(x, W, b, sigmoide)\n",
    "print(a_salida)\n",
    "print(a_salida.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b3b2e1",
   "metadata": {},
   "source": [
    "¿Qué sucede en la línea `np.dot(w, a_entrada)`? La multiplicación es entre vectores 1D, puesto que `W[:,j]` al indexar una matriz con : en la primera dimensión y 0 en la segunda dimensión, se seleccionan todos los elementos de la primera fila y el primer elemento de cada columna. Por lo tanto, np.dot() está calculando el producto interno de dos vectores 1D y no está realizando una multiplicación matricial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f51e3f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166\n",
      "[ 1 -2]\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(W[:,0],x))\n",
    "print(W[:,0])\n",
    "print(W[:,0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c91b38",
   "metadata": {},
   "source": [
    "Implementemos a continuación la versión vectorizada. Para ello trabajaremos solo con **matrices**. Además, utilizando `np.matmul()`o su equivalente, `@` reducimos también líneas de código (son las formas en las que NumPy realiza la multiplicación de matrices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cb531f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefinimos los valores.\n",
    "X_matriz = np.array([[200, 17]])     # Matriz 1x2\n",
    "W_matriz = np.array([[1, -3, 5],\n",
    "                     [-2, 4, -6]])   # Matriz 2x3\n",
    "B_matriz = np.array([[-1, 1, 2]])    # Matriz 1x3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c337a510",
   "metadata": {},
   "source": [
    "**¡Importante!** Por lo visto en el breve repaso de la multiplicación de matrices, dependiendo si multiplicamos $X*W$ o $W*X$, la primera matriz tendrá que ser su traspuesta. Es decir, que siendo todas ellas matrices columnas, en el primer caso sería $X^T*W$y en el segundo $W^T*X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a84bdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versión VECTORIZADA\n",
    "def forward_propagation_vectorizada(A_entrada, W, B, g):\n",
    "    \"\"\"\n",
    "    Calcula las activaciones de una capa.\n",
    "    \n",
    "    Argumentos:\n",
    "    ----------\n",
    "      A_entrada (ndarray (1,n))  : Matriz de datos de entrada \n",
    "      W         (ndarray (n,j))  : Matriz de pesos, n características por unidad, j unidades\n",
    "      B         (ndarray (1,j))  : Matriz de sesgo, j unidades\n",
    "      g                          : Función de activación\n",
    "      \n",
    "    Devuelve\n",
    "    ----------\n",
    "      A_salida  (ndarray (j,))   : j unidades\n",
    "    \"\"\"                               \n",
    "    Z = np.matmul(A_entrada, W) + B # equivalente a: A_entrada @ W + B\n",
    "    # Función de activación g() definida fuera de la función\n",
    "    A_salida = g(Z)               \n",
    "    return(A_salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7918dd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 1.]]\n",
      "(1, 3)\n"
     ]
    }
   ],
   "source": [
    "a_salida_vectorizada = forward_propagation_vectorizada(X_matriz, W_matriz, B_matriz, sigmoide)\n",
    "print(a_salida_vectorizada)\n",
    "print(a_salida_vectorizada.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5e191b",
   "metadata": {},
   "source": [
    "Como no podía ser de otra manera, obtenemos el mismo resultado numérico. Eso sí, fijémonos que `a_salida` es una array 1D de dimensiones (3,), mientras que `a_salida_vectorizada` es una matriz (o vector 2D) de dimensiones (1x3).\n",
    "\n",
    "Esta resulta ser una implementación muy eficiente de un paso de propagación hacia delante a través de una capa en una red neuronal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d39d33",
   "metadata": {},
   "source": [
    "<a name='3-2'></a>\n",
    "#### Implementación de las funciones de pérdida L1 y L2\n",
    "\n",
    "En optimización matemática y teoría de la decisión, una función de pérdida o función de coste (a veces también llamada función de error) es una función que asigna un suceso o valores de una o más variables a un número real que representa intuitivamente algún \"coste\" asociado al suceso. \n",
    "\n",
    "La pérdida se utiliza para evaluar el rendimiento del modelo. Cuanto mayor sea la pérdida, más diferentes serán las predicciones ($ \\hat{y} $) de los valores reales ($y$). En el aprendizaje profundo, se utilizan algoritmos de optimización como el descenso del gradiente (_Gradient Descent_) para entrenar el modelo y minimizar el coste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dd3067",
   "metadata": {},
   "source": [
    "<a name='3-2-1'></a>\n",
    "##### L1\n",
    "La función de pérdida L1, también conocida como función de pérdida por error absoluto, es la diferencia absoluta entre una predicción y el valor real, calculada para cada ejemplo de un conjunto de datos. La agregación de todos estos valores de pérdida se denomina función de coste, donde la función de coste para L1 suele ser MAE (Error Absoluto Medio).\n",
    "\n",
    "- Implementación de la versión NumPy vectorizada de la pérdida L1. Su definición es:\n",
    "$$\\begin{align*} & L_1(\\hat{y}, y) = \\sum_{i=0}^{m-1}|y^{(i)} - \\hat{y}^{(i)}| \\end{align*}\\tag{6}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "934d82b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L1(yhat, y):\n",
    "    \"\"\"\n",
    "    Argumentos: \n",
    "    yhat    – vector de tamaño m (etiquetas predichas) \n",
    "    y       – vector de tamaño m (etiquetas verdaderas) \n",
    "    \n",
    "    Devuelve: \n",
    "    perdida – el valor de la función de pérdida L1 definida anteriormente\n",
    "    \"\"\"\n",
    "    perdida = np.sum(abs(y - yhat))\n",
    "    \n",
    "    return perdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d586f8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 = 1.2\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de aplicación\n",
    "yhat = np.array([.8, 0.2, 0.1, .5, .8])\n",
    "y = np.array([1, 0, 0, 1, 1])\n",
    "print(\"L1 = \" + str(L1(yhat, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb21452",
   "metadata": {},
   "source": [
    "<a name='3-2-2'></a>\n",
    "##### L2\n",
    "\n",
    "La función de pérdida L2, también conocida como función de pérdida por error al cuadrado, es la diferencia al cuadrado entre una predicción y el valor real, calculada para cada ejemplo de un conjunto de datos. La agregación de todos estos valores de pérdida se denomina función de coste, donde la función de coste para L2 suele ser MSE (Mean of Squared Errors).\n",
    "\n",
    "- Implementación de la versión NumPy vectorizada de la pérdida L2. Hay varias formas de implementar la pérdida L2; una de ellas es utilizando la función np.dot(). Si $\\vec{x} = [x_1, x_2, ..., x_m]$, entonces np.dot($\\vec{x},\\vec{x}$) = $\\sum_{i=0}^m x_i^{2}$. \n",
    "\n",
    "$$\\begin{align*} & L_2(\\hat{y},y) = \\sum_{i=0}^{m-1}(y^{(i)} - \\hat{y}^{(i)})^2 \\end{align*}\\tag{7}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a17b95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2(yhat, y):\n",
    "    \"\"\"\n",
    "    Argumentos: \n",
    "    yhat     – vector de tamaño m (etiquetas predichas) \n",
    "    y        – vector de tamaño m (etiquetas verdaderas) \n",
    "    \n",
    "    Devuelve: \n",
    "    perdida  – el valor de la función de pérdida L2 definida anteriormente\n",
    "    \"\"\"\n",
    "    perdida = np.dot(y - yhat, y - yhat)\n",
    "    \n",
    "    return perdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3137052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 = 0.38\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de aplicación\n",
    "yhat = np.array([.8, 0.2, 0.1, .5, .8])\n",
    "y = np.array([1, 0, 0, 1, 1])\n",
    "print(\"L2 = \" + str(round(L2(yhat, y),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1e65ca",
   "metadata": {},
   "source": [
    "Otras referencias: https://realpython.com/numpy-array-programming/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
